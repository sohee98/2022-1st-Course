## An Overview of Sensor Data Analysis Process 

## (Mobile vs. Fixed Sensing Cases)



### Sensor Data Gathering & Processing

* Getting sensor data 
  * From which sensors? (e.g., motion sensors, current sensors) 
  * From where? Phone (wearable) vs. factory (stationary) 
  * How? (e.g., wireless or wired, hierarchical?) 
* Processing sensor data
  * Why? For what? (e.g., activity recognition or fault detection) í™œë™ì¸ì‹, ì˜¤ë¥˜ê°ì§€
  * How (procedure)
    * Sensor data processing pipeline: collect ğŸ¡ª segment ğŸ¡ª extractì¶”ì¶œ ğŸ¡ª classifyë¶„ë¥˜ 
      (ë°ì´í„°ê°€ ë„ˆë¬´ ë§ì•„ì„œ segmentë¥¼ ìƒì„±í•´ì•¼ í•¨)
    * Sensor fusion â€“ leveraging multiple sensors for better classification 
      ì„¼ì„œ ìœµí•©- ë” ë‚˜ì€ ë¶„ë¥˜ë¥¼ ìœ„í•´ ì—¬ëŸ¬ ì„¼ì„œ í™œìš©



### 1. Mobile Sensing with Smartphones

* Galaxy S20 Sensors
  * Accelerometer, Magnetometer(ë‚˜ì¹¨ë°˜), Gyroscope(íšŒì „ë°©í–¥), Ambient Light, Proximity(ì „í™”ì‹œ í™”ë©´ì–´ë‘ì›Œì§), Camera, Voice, Pressure, NFC, Heart Rate, Fingerprint scanner

* Applications 

  * Health and Well Being - Promoting personal fitness(UbiFit Garden, Move, Google Fit)

  * Transportation - Traffic conditions, Driving Behaviors(MIT DriveWell) 

  * Social Networking - Sensing presence(Dartmouth CenceMe) 

  * Environmental Monitoring - Measuring pollution(UCLA PIER)

- Eco-system Players

  * Multiple vendors - Apple AppStore, Google Play, Microsoft Mobile Marketplace

  * Developers - Startups, Academia, Small Research laboratories, Individuals

  * Critical mass of users

- Scale of Mobile Sensing
  * Individual - UbitFit Garden => Group - Garbage Watch =>  Community - Participatory Urbanism 

- Sensing Paradigm
  - Participatory: active sensor data collection by users ì‚¬ìš©ìì— ì˜í•œ ëŠ¥ë™ ë°ì´í„° ìˆ˜ì§‘
    - Example: managing garbage cans by <u>taking photos</u>
    - Advantages: supports complex operations
    - Challenges: Quality of data is dependent on participants
  - Opportunistic: automated sensor data collection ìë™í™”ëœ ë°ì´í„° ìˆ˜ì§‘
    - Example: collecting GPS location traces from usersâ€™ phone
    - Advantages: lowers burden placed on the user
    - Challenges: 
      - Technically hard to build â€“ people underutilized
      - Phone context problem (dynamic environments)

- Mobile Sensing Architecture

  * **Sense**
    * Programmability
      * Managing smartphone sensors with system APIs
      * Challenges: fine-grainedì •ë°€í•œ control of sensors, portabilityíœ´ëŒ€ì„± (OS & sensor variation) 
    * Continuous sensing ì—°ì† ê°ì§€
      * Resource demanding (e.g., computation, battery)
      * Energy efficient algorithms; trade-off between accuracy and energy consumption
        ì •í™•ë„ì™€ ì—ë„ˆì§€ ì†Œë¹„ê°„ì˜ ê· í˜•
    * Phone context
      * Dynamic environments affect sensor data quality ë™ì í™˜ê²½->ì„¼ì„œë°ì´í„°í’ˆì§ˆì— ì˜í–¥
      * Some solutions: Admission controls for removing noisy data, Collaborative multi-phone inference (i.e., using multiple sensors) ë‹¤ì¤‘ì„¼ì„œ ì‚¬ìš©
    * Time consuming ì‹œê°„ ì†Œëª¨
      * Most labor intensive work in sensor data science ê°€ì¥ ë…¸ë™ ì§‘ì•½ì ì¸ ì‘ì—…
      * Sensor data + label collection ì„¼ì„œ ë°ì´í„° + ë¼ë²¨ ìˆ˜ì§‘

  * **Learn**
    * Integrating sensor data ì„¼ì„œ ë°ì´í„° í†µí•©
      * Data mining and statistical analysis
    * Learning algorithms 
      * Supervised: data are hand-labeled (e.g., cooking, driving) ìˆ˜ë™ ë¼ë²¨ ì§€ì •
      * Semi-supervised: some of the data are labeled ì¼ë¶€ë§Œ ë¼ë²¨ ì§€ì •
      * Unsupervised: none of the data are labeled ë¼ë²¨ ì—†ìŒ
    * Example: human behavior and context modeling ì¸ê°„í–‰ë™ ëª¨ë¸ë§
      * Activity classification í™œë™ ë¶„ë¥˜
      * Mobility pattern analysis (place logging) ì´ë™ì„± íŒ¨í„´ ë¶„ì„
      * Noise mapping in urban environments ë„ì‹œí™˜ê²½ì˜ ë…¸ì´ì¦ˆë§¤í•‘
  * Learn : Scaling Models ëª¨ë¸ í™•ì¥í•˜ê¸°
    * Scaling model to everyday uses 
      * Dynamic environments; personal differences ë™ì  í™˜ê²½ - ê°œì¸ì°¨
      * Large scale deployment (e.g., millions of people) ëŒ€ê·œëª¨ ë°°í¬
    * Models must be adaptive and incorporate people into the process ì ì‘ë ¥, ì‚¬ëŒí†µí•©
    * If possible, exploit wisdom of crowd (or crowdsourcing) to improve data classification and solutions 
    * Challenges:
      * Lack of common machine learning toolkits for smartphones 
      * Lack of large-scale public data sets 
      * Lack of public repository for sharing datasets, code, and tools 

  * **Inform, Share, Persuasion** ì•Œë¦¼, ê³µìœ , ì„¤ë“
    * Sharing
      * Data visualization, community awareness, and social networks
        ë°ì´í„° ì‹œê°í™”, ì»¤ë®¤í‹°ë‹ˆ ì¸ì‹, ì†Œì…œ ë„¤íŠ¸ì›Œí¬
    * Personalized services ë§ì¶¤í˜• ì„œë¹„ìŠ¤
      * Profile user preferences, recommendations, persuasion ì„ í˜¸ë„, ì¶”ì²œ, ì„¤ë“
    * **Persuasive technology ì„¤ë“ ê¸°ìˆ ** â€“ systems that provide tailored feedback with the goal of changing userâ€™s behavior ì‚¬ìš©ì í–‰ë™ ë³€í™”ë¥¼ ëª©í‘œë¡œ ë§Ÿì¶¤í˜• í”¼ë“œë°±ì„ ì œê³µ
      * Motivation to change human behavior (e.g., healthcare, environmental awareness)
        ì¸ê°„ í–‰ë™ì„ ë°”ê¾¸ë ¤ëŠ” ë™ê¸° (ê±´ê°•ê´€ë¦¬, í™˜ê²½ ì¸ì‹)
      * Methods: self-reflection, goal setting, social competitions ìê¸°ë°˜ì„±, ëª©í‘œì„¤ì • 
      * Interdisciplinary research combining behavioral and social psychology with computer science í–‰ë™ì‹¬ë¦¬í•™, ì‚¬íšŒì‹¬ë¦¬í•™ + ì»´í“¨í„° ê³µí•™ ê²°í•©

* Privacy Issues ê°œì¸ ì •ë³´ ë³´í˜¸ ë¬¸ì œ
  * Respecting the privacy of the user is the most fundamental responsibility of a mobile sensing system ì‚¬ìš©ìì˜ í”„ë¼ì´ë²„ì‹œë¥¼ ì¡´ì¤‘í•˜ëŠ”ê²ƒì€ ëª¨ë°”ì¼ì„¼ì‹±ì‹œìŠ¤í…œì˜ ê°€ì¥ ê¸°ë³¸ì ì¸ ì±…ì„ì´ë‹¤.
  * Reconstruction type attacks 
    * Reverse engineering collected data to obtain invasive information 
  * Second-hand smoke problem
    * How can the privacy of third parties be effectively protected when other people wearing sensors are nearby?
    * How can mismatched privacy policies be managed when two different people are close enough to each other for their sensors to collect information?
  * Understanding of privacy issues of novel mobile and wearable technologies is required 
  * Furthermore, stronger techniques for protecting peopleâ€™s privacy are needed ê°•ë ¥í•œê¸°ìˆ í•„ìš”
  * Current solutions í˜„ì¬ ì†”ë£¨ì…˜
    * Cryptography ì•”í˜¸í™”
    * Privacy-preserving data mining ê°œì¸ ì •ë³´ ë³´í˜¸ ë°ì´í„° ë§ˆì´ë‹
    * Processing data locally versus cloud services í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ì™€ ë¹„êµí•˜ì—¬ ë¡œì»¬ì—ì„œ ë°ì´í„° ì²˜ë¦¬
    * Group sensing applications is based on user membership and/or trust relationships
      ê·¸ë£¹ ì„¼ì‹± ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ì‚¬ìš©ì ë©¤ë²„ì‹­, ì‹ ë¢°ê´€ê³„ë¥¼ ê¸°ë°˜



### 2. Case Study of Mobile Sensing: *Human Activity Recognition using Smartphones*

* Activities

  * High-level activities - giving a lecture, having a breakfast, ...
  * low-level activities - lying on a bed, standing still, running, ...

* #### Activity Recognition Process í™œë™ ì¸ì‹ í”„ë¡œì„¸ìŠ¤

  * Motion Sensors [accelerometer(xy), compass, gyroscope]

    (Data Acquisition & Pre-processing ìˆ˜ì§‘,ì „ì²˜ë¦¬)=> Sensor Data 

    (Segmentation)=> Data Segment 

    (Feature Extraction íŠ¹ì§• ì¶”ì¶œ)=> Features 

    (Model êµ¬ì¶•, ë¶„ë¥˜(ì¶”ë¡ ))=> Activity 

  <img src="md-images/image-20220308101708987.png" alt="image-20220308101708987" style="zoom: 80%;" />



* **Data Acquisition & Pre-processing** ë°ì´í„° ìˆ˜ì§‘, ì „ì²˜ë¦¬
  * Collecting a stream of sensor data (e.g., using Androidâ€™s sensor manager interface)
  * Since most sensors provide data on some regular basis, we also need to know **sampling rate** (will learn more about this during DSP sessions)
  * An accelerometer, for example, may provide a stream of tuples of real numbers representing the acceleration in x, y and z-direction with 5 Hz 
  * Cf) Androidâ€™s sensing rate configuration
    * Predefined rates: SENSOR_DELAY_NORMAL, UI, GAME, FASTEST 
      * Or, the desired delay between events in microseconds
    * Actual rate is device-dependent; e.g., Nexus 5 (Normal/UI: 15 Hz; Game: 50 Hz; Fastest: 200 Hz)
    * Note that your smart devices will not guarantee such rates, and actual rate is dependent on its operating conditions (e.g., workload) 

* **Data Segmentation**

  * For feature extraction, we need to â€œidentifyâ€ those data segments that are likely to contain information about activities (known as â€œactivity detectionâ€ or â€œspotting) 

    * **Sliding window**: using a window (=frame) of samples, and simply slide that window with fixed overlapping (e.g., 50%) 
    * Energy based: different activities have different activity â€œintensitiesâ€ (or energy) (e.g., rest vs. others) â€“ moving avg. can be used for automatic segmentation 

  * In our example, to recognize basic physical activities we collect the data of 2 seconds from the accelerometer. 

  * This corresponds to 10 readings of the acceleration data (if sampling rate is fixed to 5Hz)

    ![image-20220308102328468](md-images/image-20220308102328468.png)

<img src="md-images/image-20220308102018084.png" alt="image-20220308102018084" style="zoom:80%;" />

* **Feature Extraction** íŠ¹ì§• ì¶”ì¶œ

  * How to extract features? 

    * Signal-based features â€“ mean, variance, kurtosis 
    * Body model features â€“ exploiting prior knowledge about human kinematics 
    * Event-based features â€“ if there are any events (e.g., a sequence of eye movements â€“ saccades, fixations, or blinks) 
    * Multilevel features â€“ duration, frequency, co-occurrence, clustered data/labels 

  * In our examples, we extract the following features:

    * Average value of accelerometerâ€™s y-axis signals
    * Variance of accelerometer sensor signals 

    ![image-20220308102253874](md-images/image-20220308102253874.png)

* **Classification** ë¶„ë¥˜

  * After extracting important features from the raw data, we use a classifier to determine the current activity

  * Many different classification algorithms exist, and depending on the application domain, there may be one algorithm that shows the best performance 

  * Depending on the algorithm, the result is either a crisp decision (e.g., decision tree), or a probability distribution over activities (e.g., NaÃ¯ve Bayes) 

  * Learning algorithms: supervised vs. unsupervised (based on whether training dataset is used or not) 

    <img src="md-images/image-20220308102409539.png" alt="image-20220308102409539" style="zoom: 67%;" />

#### Summary

â€‹	<img src="md-images/image-20220308102511429.png" alt="image-20220308102511429" style="zoom: 80%;" />







